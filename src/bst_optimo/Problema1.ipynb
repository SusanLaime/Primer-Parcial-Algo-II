{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok nest-asyncio pandas networkx matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mkALeHCq6Op",
        "outputId": "92fa9eb2-c678-4b93-87e9-1bffcdd530cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.48.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Downloading streamlit-1.48.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.3.0 streamlit-1.48.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > /content/optimal_bst.py <<'PY'\n",
        "\n",
        "# optimal_bst.py\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Dict, Any, Tuple\n",
        "import math\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "@dataclass\n",
        "class Node:\n",
        "    key: str\n",
        "    index: int\n",
        "    left: Optional['Node'] = None\n",
        "    right: Optional['Node'] = None\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            'key': self.key,\n",
        "            'index': self.index,\n",
        "            'left': self.left.to_dict() if self.left else None,\n",
        "            'right': self.right.to_dict() if self.right else None,\n",
        "        }\n",
        "\n",
        "def _validate_inputs(terms: List[str], p: List[float], q: List[float]) -> None:\n",
        "    n = len(terms)\n",
        "    if len(p) != n:\n",
        "        raise ValueError(f\"len(p) debe ser {n}, pero es {len(p)}\")\n",
        "    if len(q) != n + 1:\n",
        "        raise ValueError(f\"len(q) debe ser {n+1}, pero es {len(q)}\")\n",
        "    for idx, val in enumerate(p):\n",
        "        if val < 0: raise ValueError(f\"p[{idx}] es negativo: {val}\")\n",
        "    for idx, val in enumerate(q):\n",
        "        if val < 0: raise ValueError(f\"q[{idx}] es negativo: {val}\")\n",
        "\n",
        "def _optimal_bst_clrs(terms: List[str], p: List[float], q: List[float]) -> Tuple[float, List[List[int]], List[List[float]], List[List[float]]]:\n",
        "    n = len(terms)\n",
        "    e = [[0.0]*(n+2) for _ in range(n+2)]\n",
        "    w = [[0.0]*(n+2) for _ in range(n+2)]\n",
        "    root = [[0]*(n+1) for _ in range(n+1)]\n",
        "    for i in range(1, n+2):\n",
        "        e[i][i-1] = q[i-1]\n",
        "        w[i][i-1] = q[i-1]\n",
        "    for length in range(1, n+1):\n",
        "        for i in range(1, n-length+2):\n",
        "            j = i + length - 1\n",
        "            e[i][j] = math.inf\n",
        "            w[i][j] = w[i][j-1] + p[j-1] + q[j]\n",
        "            for r in range(i, j+1):\n",
        "                t = e[i][r-1] + e[r+1][j] + w[i][j]\n",
        "                if t < e[i][j]:\n",
        "                    e[i][j] = t\n",
        "                    root[i][j] = r\n",
        "    return e[1][n], root, e, w\n",
        "\n",
        "def _optimal_bst_knuth(terms: List[str], p: List[float], q: List[float]) -> Tuple[float, List[List[int]], List[List[float]], List[List[float]]]:\n",
        "    n = len(terms)\n",
        "    e = [[0.0]*(n+2) for _ in range(n+2)]\n",
        "    w = [[0.0]*(n+2) for _ in range(n+2)]\n",
        "    root = [[0]*(n+1) for _ in range(n+1)]\n",
        "    for i in range(1, n+2):\n",
        "        e[i][i-1] = q[i-1]\n",
        "        w[i][i-1] = q[i-1]\n",
        "    for i in range(1, n+1):\n",
        "        j = i\n",
        "        w[i][j] = w[i][j-1] + p[j-1] + q[j]\n",
        "        e[i][j] = e[i][j-1] + e[j+1][j] + w[i][j]\n",
        "        root[i][j] = i\n",
        "    for length in range(2, n+1):\n",
        "        for i in range(1, n-length+2):\n",
        "            j = i + length - 1\n",
        "            w[i][j] = w[i][j-1] + p[j-1] + q[j]\n",
        "            r_start = root[i][j-1] if root[i][j-1] != 0 else i\n",
        "            r_end = root[i+1][j] if root[i+1][j] != 0 else j\n",
        "            r_start = max(r_start, i)\n",
        "            r_end = min(r_end, j)\n",
        "            e[i][j] = math.inf\n",
        "            best_r = r_start\n",
        "            for r in range(r_start, r_end+1):\n",
        "                t = e[i][r-1] + e[r+1][j] + w[i][j]\n",
        "                if t < e[i][j]:\n",
        "                    e[i][j] = t\n",
        "                    best_r = r\n",
        "            root[i][j] = best_r\n",
        "    return e[1][n], root, e, w\n",
        "\n",
        "def optimal_bst(terms: List[str], p: List[float], q: List[float], method: str = 'knuth') -> Dict[str, Any]:\n",
        "    _validate_inputs(terms, p, q)\n",
        "    method = method.lower().strip()\n",
        "    if method == 'clrs':\n",
        "        cost, root, e, w = _optimal_bst_clrs(terms, p, q)\n",
        "    elif method == 'knuth':\n",
        "        cost, root, e, w = _optimal_bst_knuth(terms, p, q)\n",
        "    else:\n",
        "        raise ValueError(\"method debe ser 'clrs' o 'knuth'.\")\n",
        "    return {'cost': cost, 'root': root, 'e': e, 'w': w}\n",
        "\n",
        "def reconstruct_tree(root_table: List[List[int]], i: int, j: int, terms: List[str]) -> Optional[Node]:\n",
        "    if i > j:\n",
        "        return None\n",
        "    r = root_table[i][j]\n",
        "    if r == 0:\n",
        "        return None\n",
        "    left = reconstruct_tree(root_table, i, r-1, terms)\n",
        "    right = reconstruct_tree(root_table, r+1, j, terms)\n",
        "    return Node(key=terms[r-1], index=r, left=left, right=right)\n",
        "\n",
        "def tables_to_dataframes(e: List[List[float]], w: List[List[float]], root: List[List[int]]) -> Dict[str, pd.DataFrame]:\n",
        "    n = len(root)-1\n",
        "    e_df = pd.DataFrame([[e[i][j] for j in range(n+2)] for i in range(1,n+2)],\n",
        "                        index=[f\"i={i}\" for i in range(1,n+2)],\n",
        "                        columns=[f\"j={j}\" for j in range(0,n+2)])\n",
        "    w_df = pd.DataFrame([[w[i][j] for j in range(n+2)] for i in range(1,n+2)],\n",
        "                        index=[f\"i={i}\" for i in range(1,n+2)],\n",
        "                        columns=[f\"j={j}\" for j in range(0,n+2)])\n",
        "    root_df = pd.DataFrame([[root[i][j] for j in range(1,n+1)] for i in range(1,n+1)],\n",
        "                           index=[f\"i={i}\" for i in range(1,n+1)],\n",
        "                           columns=[f\"j={j}\" for j in range(1,n+1)])\n",
        "    return {'e': e_df, 'w': w_df, 'root': root_df}\n",
        "\n",
        "def tree_to_networkx(root_node: Node) -> nx.DiGraph:\n",
        "    G = nx.DiGraph()\n",
        "    def _visit(node: Optional[Node]):\n",
        "        if node is None: return\n",
        "        label = f\"{node.key}\\\\n(idx={node.index})\"\n",
        "        G.add_node(node.index, label=label)\n",
        "        if node.left:\n",
        "            G.add_edge(node.index, node.left.index)\n",
        "            _visit(node.left)\n",
        "        if node.right:\n",
        "            G.add_edge(node.index, node.right.index)\n",
        "            _visit(node.right)\n",
        "    _visit(root_node)\n",
        "    return G\n",
        "\n",
        "def plot_tree_networkx(root_node: Node, figsize=(8,6)) -> plt.Figure:\n",
        "    G = tree_to_networkx(root_node)\n",
        "    pos = hierarchy_pos(G, list(G.nodes)[0]) if len(G) > 0 else {}\n",
        "    labels = nx.get_node_attributes(G, 'label')\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    nx.draw(G, pos=pos, labels=labels, with_labels=True, node_size=2000, font_size=8, arrows=False, ax=ax)\n",
        "    ax.set_axis_off()\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def hierarchy_pos(G, root=None, width=1.0, vert_gap=0.2, vert_loc=0, xcenter=0.5):\n",
        "    # función auxiliar para posiciones tipo jerarquía\n",
        "    if root is None:\n",
        "        root = list(G.nodes)[0]\n",
        "    def _hierarchy_pos(G, root, left, right, vert_loc, pos):\n",
        "        pos[root] = ((left+right)/2.0, vert_loc)\n",
        "        children = list(G.successors(root))\n",
        "        if len(children)==0:\n",
        "            return\n",
        "        step = (right-left)/len(children)\n",
        "        for i,ch in enumerate(children):\n",
        "            _hierarchy_pos(G, ch, left + i*step, left + (i+1)*step, vert_loc-vert_gap, pos)\n",
        "    pos = {}\n",
        "    _hierarchy_pos(G, root, 0, width, vert_loc, pos)\n",
        "    return pos\n",
        "\n",
        "PY"
      ],
      "metadata": {
        "id": "nJcX7Ps5q7g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > /content/streamlit_app.py <<'PY'\n",
        "\n",
        "# streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import tracemalloc\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "from optimal_bst import optimal_bst, reconstruct_tree, tables_to_dataframes, plot_tree_networkx\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import sys\n",
        "\n",
        "st.set_page_config(page_title=\"Optimal BST - Demo + Benchmark\", layout=\"wide\")\n",
        "\n",
        "st.title(\"Árbol de Búsqueda Binaria Óptimo (OBST) — Demo y Benchmark\")\n",
        "st.markdown(\"\"\"\n",
        "Calcula OBST (CLRS) / Knuth y permite ejecutar benchmarks empíricos.\n",
        "Usa el panel `Entradas` para ejecutar un caso único y el panel `Benchmark` para comparar escalado.\n",
        "\"\"\")\n",
        "\n",
        "# ---------- Utilities ----------\n",
        "def deep_getsizeof(obj, seen=None):\n",
        "    \"\"\"Estimación recursiva del tamaño en bytes de una estructura compuesta.\"\"\"\n",
        "    import sys\n",
        "    if seen is None:\n",
        "        seen = set()\n",
        "    obj_id = id(obj)\n",
        "    if obj_id in seen:\n",
        "        return 0\n",
        "    seen.add(obj_id)\n",
        "    size = sys.getsizeof(obj)\n",
        "    if isinstance(obj, dict):\n",
        "        for k, v in obj.items():\n",
        "            size += deep_getsizeof(k, seen)\n",
        "            size += deep_getsizeof(v, seen)\n",
        "    elif isinstance(obj, (list, tuple, set)):\n",
        "        for item in obj:\n",
        "            size += deep_getsizeof(item, seen)\n",
        "    return size\n",
        "\n",
        "def generate_terms(n: int):\n",
        "    return [f\"t{str(i).zfill(5)}\" for i in range(1, n+1)]\n",
        "\n",
        "def generate_probabilities(n: int, seed: int=None):\n",
        "    rnd = random.Random(seed)\n",
        "    p_raw = [rnd.random() for _ in range(n)]\n",
        "    q_raw = [rnd.random() for _ in range(n+1)]\n",
        "    total = sum(p_raw) + sum(q_raw)\n",
        "    if total == 0:\n",
        "        # fallback\n",
        "        p = [1.0/(2*n) for _ in range(n)]\n",
        "        q = [1.0/(2*(n+1)) for _ in range(n+1)]\n",
        "    else:\n",
        "        p = [v/total for v in p_raw]\n",
        "        q = [v/total for v in q_raw]\n",
        "    return p, q\n",
        "\n",
        "def measure_one_run(n:int, method:str, seed:int=None):\n",
        "    \"\"\"Ejecuta optimal_bst para un input generado y mide tiempo, memoria y tamaño de tablas.\"\"\"\n",
        "    terms = generate_terms(n)\n",
        "    p, q = generate_probabilities(n, seed=seed)\n",
        "    tracemalloc.start()\n",
        "    t0 = time.perf_counter()\n",
        "    res = optimal_bst(terms, p, q, method=method)\n",
        "    t1 = time.perf_counter()\n",
        "    current, peak = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    tables_mem = deep_getsizeof(res['e']) + deep_getsizeof(res['w']) + deep_getsizeof(res['root'])\n",
        "    return {\n",
        "        'n': n,\n",
        "        'method': method,\n",
        "        'time_s': (t1 - t0),\n",
        "        'peak_mem_bytes': peak,\n",
        "        'tables_mem_bytes': tables_mem,\n",
        "        'cost': res['cost']\n",
        "    }\n",
        "\n",
        "# ---------- Left column: Single-run / interactive ----------\n",
        "left, right = st.columns((1,1))\n",
        "\n",
        "with left:\n",
        "    st.header(\"Entradas / Ejecución individual\")\n",
        "    st.markdown(\"Ingresa términos + p + q (o usa los valores por defecto). Pulsa **Generar** para ver tablas y árbol.\")\n",
        "    method = st.selectbox(\"Método (ejecución única)\", options=[\"knuth\",\"clrs\"], index=0)\n",
        "    sort_terms = st.checkbox(\"Ordenar lexicográficamente y reordenar p\", value=True)\n",
        "    terms_txt = st.text_area(\"Términos (comma-separated)\", value=\"assert,class,def,import\", height=80)\n",
        "    p_txt = st.text_area(\"p (probabilidades exitosas, comma-separated)\", value=\"0.22,0.18,0.20,0.15\", height=60)\n",
        "    q_txt = st.text_area(\"q (probabilidades fallidas, comma-separated)\", value=\"0.02,0.03,0.03,0.05,0.12\", height=60)\n",
        "    if st.button(\"Generar\"):\n",
        "        try:\n",
        "            terms = [t.strip() for t in terms_txt.split(\",\") if t.strip()!='']\n",
        "            p = [float(x.strip()) for x in p_txt.split(\",\") if x.strip()!='']\n",
        "            q = [float(x.strip()) for x in q_txt.split(\",\") if x.strip()!='']\n",
        "            if sort_terms:\n",
        "                pairs = list(zip(terms, p))\n",
        "                pairs.sort(key=lambda x: x[0])\n",
        "                terms = [t for t,_ in pairs]\n",
        "                p = [pi for _,pi in pairs]\n",
        "                st.info(\"Términos ordenados lexicográficamente y p reordenado en el mismo orden.\")\n",
        "            st.write(f\"n = {len(terms)}  — método: {method}\")\n",
        "            tracemalloc.start()\n",
        "            t0 = time.perf_counter()\n",
        "            res = optimal_bst(terms, p, q, method=method)\n",
        "            t1 = time.perf_counter()\n",
        "            current, peak = tracemalloc.get_traced_memory()\n",
        "            tracemalloc.stop()\n",
        "            cost = res['cost']\n",
        "            st.metric(\"Costo esperado mínimo\", f\"{cost:.6f}\")\n",
        "            dfs = tables_to_dataframes(res['e'], res['w'], res['root'])\n",
        "            st.subheader(\"Tabla e (costos)\")\n",
        "            st.dataframe(dfs['e'])\n",
        "            st.subheader(\"Tabla w (probabilidades acumuladas)\")\n",
        "            st.dataframe(dfs['w'])\n",
        "            st.subheader(\"Tabla root (raíces)\")\n",
        "            st.dataframe(dfs['root'])\n",
        "            root_node = reconstruct_tree(res['root'], 1, len(terms), terms)\n",
        "            if root_node:\n",
        "                st.subheader(\"Árbol óptimo (visualización)\")\n",
        "                fig = plot_tree_networkx(root_node, figsize=(10,6))\n",
        "                st.pyplot(fig)\n",
        "            else:\n",
        "                st.write(\"No se pudo reconstruir el árbol (root vacío).\")\n",
        "            # medidas\n",
        "            st.subheader(\"Medidas empíricas (caso único)\")\n",
        "            st.write(f\"Tiempo de ejecución: {(t1-t0):.6f} s\")\n",
        "            st.write(f\"Memoria pico (tracemalloc): {peak/1024:.2f} KiB\")\n",
        "            tables_mem = deep_getsizeof(res['e']) + deep_getsizeof(res['w']) + deep_getsizeof(res['root'])\n",
        "            st.write(f\"Tamaño estimado de tablas (bytes): {tables_mem}\")\n",
        "        except Exception as exc:\n",
        "            st.error(f\"Error en la entrada o ejecución: {exc}\")\n",
        "\n",
        "# ---------- Right column: Benchmark ----------\n",
        "with right:\n",
        "    st.header(\"Benchmarking (comparativo)\")\n",
        "    st.markdown(\"\"\"\n",
        "    Ejecuta varias instancias para comparar escalado de los métodos.\n",
        "    **Precaución:** elegir tamaños grandes y muchas repeticiones puede consumir tiempo y memoria en Colab.\n",
        "    \"\"\")\n",
        "    sizes_txt = st.text_input(\"Tamaños n (comma-separated)\", value=\"10,30,60,100\")\n",
        "    methods_chk = st.multiselect(\"Métodos a comparar\", options=[\"knuth\",\"clrs\"], default=[\"knuth\",\"clrs\"])\n",
        "    repeats = st.number_input(\"Repeticiones por (n,method)\", min_value=1, max_value=20, value=3, step=1)\n",
        "    random_seed = st.number_input(\"Seed para generación aleatoria (0 para variable)\", value=0, step=1)\n",
        "    run_bench = st.button(\"Run benchmark\")\n",
        "    if run_bench:\n",
        "        try:\n",
        "            sizes = [int(x.strip()) for x in sizes_txt.split(\",\") if x.strip()!='']\n",
        "            if len(methods_chk) == 0:\n",
        "                st.error(\"Selecciona al menos un método.\")\n",
        "            else:\n",
        "                # prepare results\n",
        "                results = []\n",
        "                progress = st.progress(0)\n",
        "                total_tasks = len(sizes) * len(methods_chk) * repeats\n",
        "                task_count = 0\n",
        "                with st.spinner(\"Running benchmarks... esto puede tardar varios segundos/minutos según parámetros\"):\n",
        "                    for n in sizes:\n",
        "                        for method_b in methods_chk:\n",
        "                            for rep in range(repeats):\n",
        "                                seed = (random_seed if random_seed != 0 else None)\n",
        "                                row = measure_one_run(n, method_b, seed=seed)\n",
        "                                results.append(row)\n",
        "                                task_count += 1\n",
        "                                progress.progress(task_count / total_tasks)\n",
        "                df = pd.DataFrame(results)\n",
        "                st.success(\"Benchmark completado.\")\n",
        "                st.subheader(\"Tabla de resultados\")\n",
        "                st.dataframe(df.sort_values(['n','method']).reset_index(drop=True))\n",
        "                # Plots\n",
        "                st.subheader(\"Gráficos\")\n",
        "                # 1) time vs n (log-log)\n",
        "                fig1, ax1 = plt.subplots()\n",
        "                for m, g in df.groupby('method'):\n",
        "                    g2 = g.groupby('n')['time_s'].mean().reset_index()\n",
        "                    ax1.plot(g2['n'], g2['time_s'], marker='o', label=m)\n",
        "                ax1.set_xlabel(\"n\")\n",
        "                ax1.set_ylabel(\"time (s)\")\n",
        "                ax1.set_xscale('linear')\n",
        "                ax1.set_yscale('log')\n",
        "                ax1.set_title(\"Tiempo medio vs n (escala log en Y)\")\n",
        "                ax1.legend()\n",
        "                st.pyplot(fig1)\n",
        "                # 2) memory vs n (peak_mem_bytes mean)\n",
        "                fig2, ax2 = plt.subplots()\n",
        "                for m, g in df.groupby('method'):\n",
        "                    g2 = g.groupby('n')['peak_mem_bytes'].mean().reset_index()\n",
        "                    ax2.plot(g2['n'], g2['peak_mem_bytes']/1024.0, marker='o', label=m)  # KiB\n",
        "                ax2.set_xlabel(\"n\")\n",
        "                ax2.set_ylabel(\"peak mem (KiB)\")\n",
        "                ax2.set_title(\"Memoria pico media vs n\")\n",
        "                ax2.legend()\n",
        "                st.pyplot(fig2)\n",
        "                # 3) normalized curves: time/n^2 and time/n^3 (mean)\n",
        "                fig3, ax3 = plt.subplots(1,2, figsize=(12,4))\n",
        "                for m, g in df.groupby('method'):\n",
        "                    g2 = g.groupby('n')['time_s'].mean().reset_index()\n",
        "                    ax3[0].plot(g2['n'], g2['time_s'] / (g2['n']**2), marker='o', label=m)\n",
        "                    ax3[1].plot(g2['n'], g2['time_s'] / (g2['n']**3), marker='o', label=m)\n",
        "                ax3[0].set_xlabel(\"n\"); ax3[0].set_ylabel(\"time / n^2\"); ax3[0].set_title(\"time / n^2\")\n",
        "                ax3[1].set_xlabel(\"n\"); ax3[1].set_ylabel(\"time / n^3\"); ax3[1].set_title(\"time / n^3\")\n",
        "                ax3[0].legend(); ax3[1].legend()\n",
        "                st.pyplot(fig3)\n",
        "                # Download CSV\n",
        "                csv_buf = df.to_csv(index=False).encode('utf-8')\n",
        "                st.download_button(\"Download results CSV\", data=csv_buf, file_name=\"obst_benchmark_results.csv\", mime=\"text/csv\")\n",
        "                # basic summary text\n",
        "                st.markdown(\"**Resumen rápido:** la gráfica `time / n^2` ayuda a evaluar si la complejidad efectiva se acerca a O(n^2) (curva estable) o se aleja hacia O(n^3).\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error durante benchmark: {e}\")\n",
        "\n",
        "# ---------- Footer ----------\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Nota: en Colab el tiempo y memoria pueden variar por recursos temporales y limitaciones de la VM. Para benchmarking más estable, ejecuta localmente o en una VM dedicada.\")\n",
        "\n",
        "PY"
      ],
      "metadata": {
        "id": "fPnRcDh5rKNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "authtoken = getpass(\"Introduce tu ngrok authtoken (no se mostrará): \")\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(authtoken)\n",
        "print(\"Authtoken configurado correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dx-A2OuukQS",
        "outputId": "ee0e9918-b5fb-45d6-b3f9-c564fba55ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introduce tu ngrok authtoken (no se mostrará): ··········\n",
            "Authtoken configurado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecuta Streamlit en background y crea un túnel ngrok público\n",
        "import nest_asyncio, subprocess, time, os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# abre el túnel en el puerto 8501 y obtiene la URL pública\n",
        "public_tunnel = ngrok.connect(8501, bind_tls=True)\n",
        "print(\"URL pública (ngrok):\", public_tunnel.public_url)\n",
        "\n",
        "# lanzar streamlit en background\n",
        "cmd = \"streamlit run /content/streamlit_app.py --server.port 8501 --server.headless true\"\n",
        "proc = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "time.sleep(3)\n",
        "print(\"Streamlit lanzado en background (PID:\", proc.pid, \"). Revisa la URL pública arriba.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uL1WcR2uype",
        "outputId": "7106c695-0b3c-4257-880a-69d5582d833d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL pública (ngrok): https://b630ec55aae0.ngrok-free.app\n",
            "Streamlit lanzado en background (PID: 397 ). Revisa la URL pública arriba.\n"
          ]
        }
      ]
    }
  ]
}